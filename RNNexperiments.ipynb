{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reports the building and experimentation of a small variety of RNN's, mostly LSTM based architectures, that our group set out to construct to tackle the urbandsound8k classification task.\n",
    "Each code cell is documented with its respective functionality in the markdown cell above it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, metrics\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files opened in the code below are resultant of the feacture extraction performed in the respective notebook. To run it you must extract the features into files in the already mentioned notebook.\n",
    "\n",
    "As input for our recurrent models we chose to use the MFCC's since they translate time-series over the Cepstrum Coefficient values which are appropriate RNN inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"sets/labels_v2\"\n",
    "file_object = open(file_name,'rb')  \n",
    "labels = pickle.load(file_object) \n",
    "file_name = \"sets/mfcc_data_v2\"\n",
    "file_object = open(file_name,'rb')  \n",
    "mfcc = pickle.load(file_object) \n",
    "file_name = \"sets/fold_pointers_v2\"\n",
    "file_object = open(file_name,'rb')  \n",
    "fold_pointer = pickle.load(file_object) \n",
    "file_name = \"sets/spec_data_shared\"\n",
    "file_object = open(file_name,'rb')\n",
    "spectrogram = pickle.load(file_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of MFCC array to be given as input to RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 321)\n"
     ]
    }
   ],
   "source": [
    "shapers=(mfcc.shape[1],mfcc.shape[2])\n",
    "print(shapers)\n",
    "#labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset splitting into folds. Details on how this is done are found in the feature extraction notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "listmfcc=[]\n",
    "listlabels=[]\n",
    "c=0\n",
    "listspectrogram=[]\n",
    "for i in range(10):\n",
    "    j=fold_pointer[i+1]-1\n",
    "    templabels=[]\n",
    "    tempmfcc=[]\n",
    "    while(c<j):\n",
    "        tempmfcc.append(mfcc[c])\n",
    "        templabels.append(labels[c])\n",
    "        c+=1\n",
    "    #listspectrogram.append(np.array(spectrogram[i]))\n",
    "    listmfcc.append(np.array(tempmfcc))\n",
    "    listlabels.append(np.array(templabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some utility functions regarding the training procedure as well as the main training pipeline.\n",
    "The histories and scores of the passed model will be stored for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'sets/checkpoint'\n",
    "metric='sparse_categorical_accuracy'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=metric,\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=0)\n",
    "\n",
    "def crossvalidation_10fold(model_checkpoint_callback,model,listmfcc,listlabels,epocas,nome,bs=32):\n",
    "    mean_acc=0\n",
    "    #reinitialize(model)\n",
    "    for k in range(10):\n",
    "            model.load_weights('sets/.h5')\n",
    "            #print(\"K = \",k)\n",
    "            for t in range(10):\n",
    "                if (t!=k):\n",
    "                    if(k==0):\n",
    "                        Xtrain=listmfcc[1]\n",
    "                        Ytrain=listlabels[1]\n",
    "                        continue\n",
    "                    if (t==0):\n",
    "                        Xtrain=listmfcc[0]\n",
    "                        Ytrain=listlabels[0]\n",
    "                    np.concatenate((Xtrain,listmfcc[t]))\n",
    "                    np.concatenate((Ytrain,listlabels[t]))\n",
    "                    continue\n",
    "                Xtest=np.array(listmfcc[k])\n",
    "                Ytest=np.array(listlabels[k])\n",
    "            history=model.fit(Xtrain,Ytrain,epochs=epocas,batch_size=bs,callbacks=[model_checkpoint_callback],validation_data=(Xtest,Ytest))    \n",
    "            scores = model.evaluate(Xtest,Ytest,verbose=0)\n",
    "            print(f\"Test accuracy {k} fold: {scores[1]}  TestLoss: {scores[0]}\")\n",
    "            mean_acc+=scores[1]/10\n",
    "            with open('histories/'+nome+'_history'+'_fold'+str(k+1), 'wb') as file:\n",
    "                model_history= History_trained_model(history.history, history.epoch, history.params)\n",
    "                pickle.dump(model_history, file, pickle.HIGHEST_PROTOCOL)\n",
    "            with open('scores/'+nome+'_score'+'_fold'+str(k+1),'wb') as file:\n",
    "                pickle.dump(scores,file,pickle.HIGHEST_PROTOCOL)\n",
    "    return history,scores,mean_acc\n",
    "\n",
    "\n",
    "def reinitialize(model):\n",
    "    for l in model.layers:\n",
    "        if hasattr(l,\"kernel_initializer\"):\n",
    "            l.kernel.assign(l.kernel_initializer(tf.shape(l.kernel)))\n",
    "        if hasattr(l,\"bias_initializer\"):\n",
    "            l.bias.assign(l.bias_initializer(tf.shape(l.bias)))\n",
    "        if hasattr(l,\"recurrent_initializer\"):\n",
    "            l.recurrent_kernel.assign(l.recurrent_initializer(tf.shape(l.recurrent_kernel)))\n",
    "\n",
    "class History_trained_model(object):\n",
    "    def __init__(self, history, epoch, params):\n",
    "        self.history = history\n",
    "        self.epoch = epoch\n",
    "        self.params = params\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard LSTM model approach follows. We use 40 LSTM units given the fact we're dealing with 40 MFCC's, so matching the nÂº of features to the number of units, as expected.\n",
    "The dropout rate is selected to 0.2, sugestion by Yang, et Al(2019).\n",
    "Softmax and Hyperbolic Tangent Layers are standard procedure in RNN's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 40)                57920     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                410       \n",
      "                                                                 \n",
      " softmax_6 (Softmax)         (None, 10)                0         \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,330\n",
      "Trainable params: 58,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bilstm=keras.Sequential([layers.Input(shape=shapers)])\n",
    "bilstm.add(layers.LSTM(40,dropout=0.2))    # dropout suggested by Yang et Al, 40 units for n_mfccs \n",
    "bilstm.add(layers.Dense(10))               # number of labels\n",
    "bilstm.add(layers.Softmax())\n",
    "bilstm.add(layers.Activation(keras.activations.tanh))    \n",
    "bilstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we're doing a brief hyperparameter assessment in order to choose what Loss and Optimizer to stick with when building new models, just for referrence.\n",
    " A thourough and definitive hyperparameter tuning will be held in the final model assessment and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: KLDivergence Optimizer: adam\n",
      "Test accuracy 0 fold: 0.10194730758666992  TestLoss: 20.42441177368164\n",
      "Test accuracy 1 fold: 0.09684684872627258  TestLoss: 20.46504783630371\n",
      "Test accuracy 2 fold: 0.12324324250221252  TestLoss: 20.567270278930664\n",
      "Test accuracy 3 fold: 0.11818181723356247  TestLoss: 20.73112678527832\n",
      "Test accuracy 4 fold: 0.10042735189199448  TestLoss: 20.596141815185547\n",
      "Test accuracy 5 fold: 0.12636694312095642  TestLoss: 20.25790023803711\n",
      "Test accuracy 6 fold: 0.12291169166564941  TestLoss: 20.307964324951172\n",
      "Test accuracy 7 fold: 0.08010012656450272  TestLoss: 20.173641204833984\n",
      "Test accuracy 8 fold: 0.08700980246067047  TestLoss: 20.233579635620117\n",
      "Test accuracy 9 fold: 0.08721625059843063  TestLoss: 20.304584503173828\n",
      "Mean acc: 0.10442513823509217\n",
      "Loss: KLDivergence Optimizer: sgd\n",
      "Test accuracy 0 fold: 0.1111111119389534  TestLoss: 20.417808532714844\n",
      "Test accuracy 1 fold: 0.10472972691059113  TestLoss: 20.462644577026367\n",
      "Test accuracy 2 fold: 0.12216216325759888  TestLoss: 20.56646156311035\n",
      "Test accuracy 3 fold: 0.09898989647626877  TestLoss: 20.730260848999023\n",
      "Test accuracy 4 fold: 0.09615384787321091  TestLoss: 20.595773696899414\n",
      "Test accuracy 5 fold: 0.10935601592063904  TestLoss: 20.257551193237305\n",
      "Test accuracy 6 fold: 0.09904534369707108  TestLoss: 20.307701110839844\n",
      "Test accuracy 7 fold: 0.08760951459407806  TestLoss: 20.173391342163086\n",
      "Test accuracy 8 fold: 0.11519607901573181  TestLoss: 20.233484268188477\n",
      "Test accuracy 9 fold: 0.08721625059843063  TestLoss: 20.30441665649414\n",
      "Mean acc: 0.10315699502825736\n",
      "Loss: SparseCategoricalCrossentropy Optimizer: adam\n",
      "Test accuracy 0 fold: 0.21305841207504272  TestLoss: 2.442922353744507\n",
      "Test accuracy 1 fold: 0.19369369745254517  TestLoss: 2.3267197608947754\n",
      "Test accuracy 2 fold: 0.16756756603717804  TestLoss: 2.5421390533447266\n",
      "Test accuracy 3 fold: 0.1666666716337204  TestLoss: 2.4230406284332275\n",
      "Test accuracy 4 fold: 0.21260683238506317  TestLoss: 2.281926155090332\n",
      "Test accuracy 5 fold: 0.20291616022586823  TestLoss: 2.2627131938934326\n",
      "Test accuracy 6 fold: 0.14200477302074432  TestLoss: 2.596409797668457\n",
      "Test accuracy 7 fold: 0.15394242107868195  TestLoss: 2.524948835372925\n",
      "Test accuracy 8 fold: 0.24264705181121826  TestLoss: 2.1614341735839844\n",
      "Test accuracy 9 fold: 0.21385902166366577  TestLoss: 2.2019431591033936\n",
      "Mean acc: 0.1908962607383728\n",
      "Loss: SparseCategoricalCrossentropy Optimizer: sgd\n",
      "Test accuracy 0 fold: 0.8510882258415222  TestLoss: 0.7400673031806946\n",
      "Test accuracy 1 fold: 0.19144144654273987  TestLoss: 2.3357455730438232\n",
      "Test accuracy 2 fold: 0.1524324268102646  TestLoss: 2.663918972015381\n",
      "Test accuracy 3 fold: 0.16565656661987305  TestLoss: 2.4906182289123535\n",
      "Test accuracy 4 fold: 0.21474358439445496  TestLoss: 2.3388538360595703\n",
      "Test accuracy 5 fold: 0.2150668352842331  TestLoss: 2.312140464782715\n",
      "Test accuracy 6 fold: 0.1360381841659546  TestLoss: 2.652326822280884\n",
      "Test accuracy 7 fold: 0.1639549434185028  TestLoss: 2.640298366546631\n",
      "Test accuracy 8 fold: 0.23529411852359772  TestLoss: 2.1751596927642822\n",
      "Test accuracy 9 fold: 0.2222222238779068  TestLoss: 2.260317087173462\n",
      "Mean acc: 0.254793855547905\n"
     ]
    }
   ],
   "source": [
    "epocas=30\n",
    "for l in [\"KLDivergence\",\"SparseCategoricalCrossentropy\"]:\n",
    "    for o in [\"adam\",\"sgd\"]: #adam or rmsprop?\n",
    "        bilstm.compile(optimizer=o,loss=l,metrics=[metrics.SparseCategoricalAccuracy()])\n",
    "        bilstm.save_weights('sets/.h5')\n",
    "        print(f\"Loss: {l} Optimizer: {o}\")\n",
    "        history,scores,mean_acc=crossvalidation_10fold(model_checkpoint_callback,bilstm,listmfcc,listlabels,epocas,'sdlstm')\n",
    "        print(f\"Mean acc: {mean_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the results obtained by the different hyperparameters choice, we're sticking with the Sparse Categorical Crossentropy as the Loss and ADAM  for Optimizer, because of its stability. \n",
    "\n",
    "Adding L2 normalization to the Fully Connected layers and making the LSTM cells Bidirectional, we shall train the model again in order to compare results.\n",
    "\n",
    "We see how setting stateful=True could yield better results, since a given window in one example could give important information for the subsequent examples. In order to do that we would've need to specify a batch size, however. Since the folds have different sizes and this feature only being discovered in a late stage of the project, due to all the constraints associated with trying this approach in this stage we shall leave this finding for further development, not incorporating in this project's instance.\n",
    "\n",
    "It is also worth mentioning that we tried to calculate the AUC-ROC for each class which didn't work for some output related reason. Keras.Metrics is suited for such and the commented tail of the compile command shows the syntax to carry such operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_5 (Bidirectio  (None, 80)               115840    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                810       \n",
      "                                                                 \n",
      " softmax_7 (Softmax)         (None, 10)                0         \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 116,650\n",
      "Trainable params: 116,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test accuracy 0 fold: 0.2164948433637619  TestLoss: 2.668415069580078\n",
      "Test accuracy 1 fold: 0.18468467891216278  TestLoss: 2.5990254878997803\n",
      "Test accuracy 2 fold: 0.1945945918560028  TestLoss: 2.7188594341278076\n",
      "Test accuracy 3 fold: 0.21111111342906952  TestLoss: 2.6011006832122803\n",
      "Test accuracy 4 fold: 0.2232905924320221  TestLoss: 2.4779164791107178\n",
      "Test accuracy 5 fold: 0.21628189086914062  TestLoss: 2.6233582496643066\n",
      "Test accuracy 6 fold: 0.1718377023935318  TestLoss: 2.811174154281616\n",
      "Test accuracy 7 fold: 0.17146432399749756  TestLoss: 2.852733612060547\n",
      "Test accuracy 8 fold: 0.26225489377975464  TestLoss: 2.5265822410583496\n",
      "Test accuracy 9 fold: 0.23416964709758759  TestLoss: 2.4816181659698486\n",
      "Mean acc: 0.20861842781305315\n"
     ]
    }
   ],
   "source": [
    "bilstm=keras.Sequential([layers.Input(shape=shapers)])\n",
    "bilstm.add(layers.Bidirectional(layers.LSTM(40,dropout=0.2)))     # dropout suggested by Yang et Al, 40 for n_mfcc's, pensar em bilLSTM\n",
    "bilstm.add(layers.Dense(10,kernel_regularizer='l2'))               # number of labels\n",
    "bilstm.add(layers.Softmax())\n",
    "bilstm.add(layers.Activation(keras.activations.tanh))    # why not sigmoid?!\n",
    "bilstm.summary()\n",
    "\n",
    "epocas=50\n",
    "bilstm.compile(optimizer='adam',loss='SparseCategoricalCrossentropy',metrics=[metrics.SparseCategoricalAccuracy()])#,metrics.AUC(multi_label=True,num_labels=10),])\n",
    "bilstm.save_weights('sets/.h5')\n",
    "history,scores,mean_acc=crossvalidation_10fold(model_checkpoint_callback,bilstm,listmfcc,listlabels,epocas,'bilstm')\n",
    "print(f\"Mean acc: {mean_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These changes didn't make much for the model's test accuracy as a trade off for twice the parameter space. They would, howeever, be later reutilized in some subsequent architectures.\n",
    "\n",
    "The next architecture proposed is based on TimeDistributed Layers. These are Fully Connected Layers stemming from two parallel LSTM cell sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 40, 321)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 40, 40)       57920       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 40, 40)       57920       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 40, 80)       0           ['lstm_1[0][0]',                 \n",
      "                                                                  'lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 40, 80)      6480        ['concatenate[0][0]']            \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3200)         0           ['time_distributed[0][0]']       \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           32010       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " softmax_1 (Softmax)            (None, 10)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 10)           0           ['softmax_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 154,330\n",
      "Trainable params: 154,330\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Test accuracy 0 fold: 0.32646048069000244  TestLoss: 4.93309211730957\n",
      "Test accuracy 1 fold: 0.4121621549129486  TestLoss: 2.9597270488739014\n",
      "Test accuracy 2 fold: 0.3243243098258972  TestLoss: 3.5300402641296387\n",
      "Test accuracy 3 fold: 0.269696980714798  TestLoss: 3.5456459522247314\n",
      "Test accuracy 4 fold: 0.4166666567325592  TestLoss: 3.058931589126587\n",
      "Test accuracy 5 fold: 0.2952612340450287  TestLoss: 5.2178850173950195\n",
      "Test accuracy 6 fold: 0.36873507499694824  TestLoss: 3.2991862297058105\n",
      "Test accuracy 7 fold: 0.37922403216362  TestLoss: 4.262883186340332\n",
      "Test accuracy 8 fold: 0.3174019753932953  TestLoss: 7.285433292388916\n",
      "Test accuracy 9 fold: 0.3655914068222046  TestLoss: 3.717947483062744\n",
      "Mean acc: 0.3475524306297302\n"
     ]
    }
   ],
   "source": [
    "input=layers.Input(shape=shapers)\n",
    "lc1=layers.LSTM(40,dropout=0.2,return_sequences=True)(input)  \n",
    "lc2=layers.LSTM(40,dropout=0.2,return_sequences=True)(input)                        \n",
    "concatenated=layers.concatenate([lc1,lc2])\n",
    "td=layers.TimeDistributed(layers.Dense(80))(concatenated)\n",
    "f=layers.Flatten()(td)            # number of labels\n",
    "dense=layers.Dense(10,kernel_regularizer='l2')(f)\n",
    "sft=layers.Softmax()(dense)\n",
    "th=layers.Activation(keras.activations.tanh)(sft)    # why not sigmoid?!\n",
    "lstm=keras.Model(inputs=input,outputs=th)\n",
    "lstm.summary()\n",
    "\n",
    "epocas=50\n",
    "lstm.compile(optimizer='adam',loss='SparseCategoricalCrossentropy',metrics=[metrics.SparseCategoricalAccuracy()])#,metrics.AUC(multi_label=True,num_labels=10)])\n",
    "lstm.save_weights('sets/.h5')\n",
    "history,scores,mean_acc=crossvalidation_10fold(model_checkpoint_callback,lstm,listmfcc,listlabels,epocas,'tdlstm')\n",
    "print(f\"Mean acc: {mean_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've seen this change yielded an significant increase in accuracy comparing to the previous and first proposals, scaling the parameter count with a factor of 3/2 (only!) and 3 respectively.\n",
    "\n",
    "Let us now try to implement the previous setting with two Bidirectional Loops consisting in twice the amount of LSTM Units, basically adding a cell equal to the already existing one to feed backwards. These will have their input merged and the remaining Layer sequence is the same as the previous proposal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 40, 321)]    0           []                               \n",
      "                                                                                                  \n",
      " bidirectional_6 (Bidirectional  (None, 40, 80)      115840      ['input_10[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_7 (Bidirectional  (None, 40, 80)      115840      ['input_10[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 40, 160)      0           ['bidirectional_6[0][0]',        \n",
      "                                                                  'bidirectional_7[0][0]']        \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDistri  (None, 40, 80)      12880       ['concatenate_2[0][0]']          \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 3200)         0           ['time_distributed_2[0][0]']     \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 10)           32010       ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " softmax_8 (Softmax)            (None, 10)           0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 10)           0           ['softmax_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 276,570\n",
      "Trainable params: 276,570\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Test accuracy 0 fold: 0.34937000274658203  TestLoss: 4.618793487548828\n",
      "Test accuracy 1 fold: 0.32770270109176636  TestLoss: 4.064713954925537\n",
      "Test accuracy 2 fold: 0.3145945966243744  TestLoss: 5.303465843200684\n",
      "Test accuracy 3 fold: 0.2545454502105713  TestLoss: 4.0936994552612305\n",
      "Test accuracy 4 fold: 0.36858972907066345  TestLoss: 3.668365716934204\n",
      "Test accuracy 5 fold: 0.27946537733078003  TestLoss: 4.760844707489014\n",
      "Test accuracy 6 fold: 0.36992838978767395  TestLoss: 4.505277633666992\n",
      "Test accuracy 7 fold: 0.39299124479293823  TestLoss: 4.448493957519531\n",
      "Test accuracy 8 fold: 0.41299018263816833  TestLoss: 3.204679012298584\n",
      "Test accuracy 9 fold: 0.37514933943748474  TestLoss: 3.5276846885681152\n",
      "Mean acc: 0.3445327013731003\n"
     ]
    }
   ],
   "source": [
    "input=layers.Input(shape=shapers)\n",
    "lc11=layers.LSTM(40,dropout=0.2,return_sequences=True)\n",
    "lc12=layers.LSTM(40,dropout=0.2,return_sequences=True,go_backwards=True)\n",
    "lc21=layers.LSTM(40,dropout=0.2,return_sequences=True)\n",
    "lc22=layers.LSTM(40,dropout=0.2,return_sequences=True,go_backwards=True)\n",
    "b1=layers.Bidirectional(lc11, backward_layer=lc12)(input)  \n",
    "b2=layers.Bidirectional(lc21, backward_layer=lc22)(input)                            \n",
    "concatenated=layers.concatenate([b1,b2])\n",
    "td=layers.TimeDistributed(layers.Dense(80))(concatenated)\n",
    "f=layers.Flatten()(td)            # number of labels\n",
    "dense=layers.Dense(10,kernel_regularizer='l2')(f)\n",
    "sft=layers.Softmax()(dense)\n",
    "th=layers.Activation(keras.activations.tanh)(sft)    # why not sigmoid?!\n",
    "lstm=keras.Model(inputs=input,outputs=th)\n",
    "lstm.summary()\n",
    "\n",
    "epocas=50\n",
    "lstm.compile(optimizer='adam',loss='SparseCategoricalCrossentropy',metrics=[metrics.SparseCategoricalAccuracy()])\n",
    "lstm.save_weights('sets/.h5')\n",
    "history,scores,mean_acc=crossvalidation_10fold(model_checkpoint_callback,lstm,listmfcc,listlabels,epocas,'btdlsm')\n",
    "print(f\"Mean acc: {mean_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now observe that the results didn't improve in terms of test accuracy.\n",
    "\n",
    "For our last experiment, we tried to mimmick an Attention Mechanism in a very ad-hoc implementation to see what results it might yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 40, 321)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 40, 40)       57920       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 40, 40)       12960       ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 40, 40)       12960       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, 40, 40)       12960       ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 40, 40)       12960       ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 40, 40)       12960       ['lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  (None, 40, 40)       12960       ['lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)                  (None, 40, 40)       12960       ['lstm_6[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)                  (None, 40, 40)       12960       ['lstm_7[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)                  (None, 40, 40)       12960       ['lstm_8[0][0]']                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 40, 40)       0           ['lstm[0][0]',                   \n",
      "                                                                  'lstm_9[0][0]']                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 40, 40)       0           ['lstm_1[0][0]',                 \n",
      "                                                                  'lstm_9[0][0]']                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 40, 40)       0           ['lstm_2[0][0]',                 \n",
      "                                                                  'lstm_9[0][0]']                 \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 40, 40)       0           ['lstm_3[0][0]',                 \n",
      "                                                                  'lstm_9[0][0]']                 \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 40, 40)       0           ['lstm_4[0][0]',                 \n",
      "                                                                  'lstm_9[0][0]']                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 40, 40)       0           ['lstm_5[0][0]',                 \n",
      "                                                                  'lstm_9[0][0]']                 \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 40, 40)       0           ['lstm_6[0][0]',                 \n",
      "                                                                  'lstm_9[0][0]']                 \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 40, 40)       0           ['lstm_7[0][0]',                 \n",
      "                                                                  'lstm_9[0][0]']                 \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 40, 40)       0           ['lstm_8[0][0]',                 \n",
      "                                                                  'lstm_9[0][0]']                 \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (10, None, 40, 40)   0           ['add[0][0]',                    \n",
      "                                                                  'add_1[0][0]',                  \n",
      "                                                                  'add_2[0][0]',                  \n",
      "                                                                  'add_3[0][0]',                  \n",
      "                                                                  'add_4[0][0]',                  \n",
      "                                                                  'add_5[0][0]',                  \n",
      "                                                                  'add_6[0][0]',                  \n",
      "                                                                  'add_7[0][0]',                  \n",
      "                                                                  'add_8[0][0]',                  \n",
      "                                                                  'lstm_9[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 40, 40)      0           ['softmax[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 40, 40)      0           ['softmax[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 40, 40)      0           ['softmax[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 40, 40)      0           ['softmax[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 40, 40)      0           ['softmax[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  (None, 40, 40)      0           ['softmax[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  (None, 40, 40)      0           ['softmax[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7 (Sl  (None, 40, 40)      0           ['softmax[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8 (Sl  (None, 40, 40)      0           ['softmax[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_9 (Sl  (None, 40, 40)      0           ['softmax[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 40, 40)       0           ['lstm[0][0]',                   \n",
      "                                                                  'tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 40, 40)       0           ['lstm_1[0][0]',                 \n",
      "                                                                  'tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 40, 40)       0           ['lstm_2[0][0]',                 \n",
      "                                                                  'tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 40, 40)       0           ['lstm_3[0][0]',                 \n",
      "                                                                  'tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 40, 40)       0           ['lstm_4[0][0]',                 \n",
      "                                                                  'tf.__operators__.getitem_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 40, 40)       0           ['lstm_5[0][0]',                 \n",
      "                                                                  'tf.__operators__.getitem_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 40, 40)       0           ['lstm_6[0][0]',                 \n",
      "                                                                  'tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 40, 40)       0           ['lstm_7[0][0]',                 \n",
      "                                                                  'tf.__operators__.getitem_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)          (None, 40, 40)       0           ['lstm_8[0][0]',                 \n",
      "                                                                  'tf.__operators__.getitem_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " multiply_9 (Multiply)          (None, 40, 40)       0           ['lstm_9[0][0]',                 \n",
      "                                                                  'tf.__operators__.getitem_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 40, 400)      0           ['multiply[0][0]',               \n",
      "                                                                  'multiply_1[0][0]',             \n",
      "                                                                  'multiply_2[0][0]',             \n",
      "                                                                  'multiply_3[0][0]',             \n",
      "                                                                  'multiply_4[0][0]',             \n",
      "                                                                  'multiply_5[0][0]',             \n",
      "                                                                  'multiply_6[0][0]',             \n",
      "                                                                  'multiply_7[0][0]',             \n",
      "                                                                  'multiply_8[0][0]',             \n",
      "                                                                  'multiply_9[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 16000)        0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           160010      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " softmax_1 (Softmax)            (None, 10)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 10)           0           ['softmax_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 334,570\n",
      "Trainable params: 334,570\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Test accuracy 0 fold: 0.35395190119743347  TestLoss: 2.4190077781677246\n",
      "Test accuracy 1 fold: 0.32319819927215576  TestLoss: 2.277071714401245\n",
      "Test accuracy 2 fold: 0.2778378427028656  TestLoss: 2.664247751235962\n",
      "Test accuracy 3 fold: 0.26868686079978943  TestLoss: 2.5729124546051025\n",
      "Test accuracy 4 fold: 0.3333333432674408  TestLoss: 2.170933961868286\n",
      "Test accuracy 5 fold: 0.26731470227241516  TestLoss: 2.7613437175750732\n",
      "Test accuracy 6 fold: 0.31622910499572754  TestLoss: 2.355153799057007\n",
      "Test accuracy 7 fold: 0.3191489279270172  TestLoss: 2.4206795692443848\n",
      "Test accuracy 8 fold: 0.3223039209842682  TestLoss: 2.4509878158569336\n",
      "Test accuracy 9 fold: 0.3727598488330841  TestLoss: 2.3336215019226074\n",
      "Mean acc: 0.3154764652252197\n"
     ]
    }
   ],
   "source": [
    "input=layers.Input(shape=shapers)\n",
    "lc1=layers.LSTM(40,dropout=0.2,return_sequences=True)(input)  \n",
    "lc2=layers.LSTM(40,dropout=0.2,return_sequences=True)(lc1)\n",
    "lc3=layers.LSTM(40,dropout=0.2,return_sequences=True)(lc2)\n",
    "lc4=layers.LSTM(40,dropout=0.2,return_sequences=True)(lc3)  \n",
    "lc5=layers.LSTM(40,dropout=0.2,return_sequences=True)(lc4)\n",
    "lc6=layers.LSTM(40,dropout=0.2,return_sequences=True)(lc5)\n",
    "lc7=layers.LSTM(40,dropout=0.2,return_sequences=True)(lc6)  \n",
    "lc8=layers.LSTM(40,dropout=0.2,return_sequences=True)(lc7)\n",
    "lc9=layers.LSTM(40,dropout=0.2,return_sequences=True)(lc8)\n",
    "lc10=layers.LSTM(40,dropout=0.2,return_sequences=True)(lc9)  \n",
    "add1=layers.Add()([lc1,lc10])\n",
    "add2=layers.Add()([lc2,lc10])\n",
    "add3=layers.Add()([lc3,lc10])\n",
    "add4=layers.Add()([lc4,lc10])\n",
    "add5=layers.Add()([lc5,lc10])\n",
    "add6=layers.Add()([lc6,lc10])\n",
    "add7=layers.Add()([lc7,lc10])\n",
    "add8=layers.Add()([lc8,lc10])\n",
    "add9=layers.Add()([lc9,lc10])\n",
    "#conc=layers.Concatenate()([add1,add2,add3,add4,add5,add6,add7,add8,add9,lc10])\n",
    "sft=layers.Softmax()([add1,add2,add3,add4,add5,add6,add7,add8,add9,lc10])\n",
    "m1=layers.Multiply()([lc1,sft[0]])\n",
    "m2=layers.Multiply()([lc2,sft[1]])\n",
    "m3=layers.Multiply()([lc3,sft[2]])\n",
    "m4=layers.Multiply()([lc4,sft[3]])\n",
    "m5=layers.Multiply()([lc5,sft[4]])\n",
    "m6=layers.Multiply()([lc6,sft[5]])\n",
    "m7=layers.Multiply()([lc7,sft[6]])\n",
    "m8=layers.Multiply()([lc8,sft[7]])\n",
    "m9=layers.Multiply()([lc9,sft[8]])\n",
    "m10=layers.Multiply()([lc10,sft[9]])\n",
    "conc=layers.Concatenate()([m1,m2,m3,m4,m5,m6,m7,m8,m9,m10])\n",
    "flt=layers.Flatten('channels_first')(conc)\n",
    "dense=layers.Dense(10,kernel_regularizer='l2')(flt)\n",
    "sft=layers.Softmax()(dense)\n",
    "th=layers.Activation(keras.activations.tanh)(sft)    \n",
    "lstm=keras.Model(inputs=input,outputs=th)\n",
    "lstm.summary()\n",
    "\n",
    "epocas=50\n",
    "lstm.compile(optimizer='adam',loss='SparseCategoricalCrossentropy',metrics=[metrics.SparseCategoricalAccuracy()])#,metrics.AUC(),metrics.Precision(),metrics.Recall()])\n",
    "lstm.save_weights('sets/.h5')\n",
    "history,scores,mean_acc=crossvalidation_10fold(model_checkpoint_callback,lstm,listmfcc,listlabels,epocas,'amlstm')\n",
    "print(f\"Mean acc: {mean_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model results weren't better than the already implemented architectures plus an associated cost of twice the trainable parameters. Nevertheless it was an interesting exercise and deeper analysis could hold interesting showings regarding the network's behaviour (or not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code cells we calculate the mean accuracy and standard deviation for each model in the 10-fold crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "def std_dev(scores):\n",
    "    mean=0\n",
    "    for i in range(10):\n",
    "        mean+=scores[i][1]\n",
    "    mean/=10\n",
    "    min_diff=float('inf')\n",
    "    min_diffi=0\n",
    "    sum=0\n",
    "    for i in range(10):\n",
    "        diff=(mean-scores[i][1])**2\n",
    "        sum+=diff\n",
    "        if diff<min_diff:\n",
    "            min_diff=diff\n",
    "            min_diffi=i\n",
    "    s=math.sqrt(sum/9)\n",
    "    return s,min_diffi,mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Model   |     Mean Accuracy          |    Std Deviation\n",
      "--------------------------------------------------------------------------------\n",
      "bilstm  |   0.20861842781305312      |     0.02862541465313222\n",
      "--------------------------------------------------------------------------------\n",
      "tdlstm  |   0.34755243062973024      |     0.04878262255597305\n",
      "--------------------------------------------------------------------------------\n",
      "btdlsm  |   0.34453270137310027      |     0.05025503602116361\n",
      "--------------------------------------------------------------------------------\n",
      "amlstm  |   0.3154764652252197      |     0.03516057527082268\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "historiesd=[]\n",
    "scoresd=[]\n",
    "find=[]\n",
    "print('================================================================================')\n",
    "print('Model   |     Mean Accuracy          |    Std Deviation')\n",
    "print('--------------------------------------------------------------------------------')\n",
    "for name in ['bilstm','tdlstm','btdlsm','amlstm']:\n",
    "    scores=[]\n",
    "    histories=[]\n",
    "    for i in range(1, 11):\n",
    "        with open('histories/'+name+'_history'+'_fold' + str(i), 'rb') as file:\n",
    "            history=pickle.load(file)\n",
    "            histories.append(history)\n",
    "        with open('scores/'+name+'_score'+'_fold'+str(i),'rb') as files:\n",
    "            score=pickle.load(files)\n",
    "            scores.append(score)\n",
    "    op=std_dev(scores)\n",
    "    find.append(op[1])\n",
    "    scoresd.append(scores)\n",
    "    historiesd.append(scores)\n",
    "    print(name+\"  |   \"+str(op[2])+\"      |     \"+str(op[0]))\n",
    "    print('--------------------------------------------------------------------------------')\n",
    "print('================================================================================')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows the general results for each model. We shall now assess each model's training behaviour in the fold which fits closer with the mean values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next plots are the train/test loss comparison over epoch for the trained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "name='bilstm'\n",
    "with open('histories/'+name+'_history'+'_fold' + str(find[0]+1), 'rb') as file:\n",
    "    history=pickle.load(file)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Loss','Test Loss'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at this graph we can conclude that the model is overfitting after the 5th epoch and further training without any alterations or parameter regularization would futile. This result is given by the distance between the test/training loss curves as the train loss decreases and the test loss increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Distributed LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "name='tdlstm'\n",
    "with open('histories/'+name+'_history'+'_fold' + str(find[1]+1), 'rb') as file:\n",
    "    history=pickle.load(file)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Loss','Test Loss'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude from the results above that further training could yield better results. We'll get to this topic later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Distributed BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "name='btdlsm'\n",
    "with open('histories/'+name+'_history'+'_fold' + str(find[2]+1), 'rb') as file:\n",
    "    history=pickle.load(file)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Loss','Test Loss'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This curve shows the overfitting nature combined with the fold data distribution in an increasing mismatch of training and test performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Module LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "name='amlstm'\n",
    "with open('histories/'+name+'_history'+'_fold' + str(find[3]+1), 'rb') as file:\n",
    "    history=pickle.load(file)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Loss','Test Loss'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The erratic nature of the Test Loss curve doesn't give away much information. Maybe training with more epochs wouldn't get better results at all and an early stopping with a low patience value would suit best this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Last Take"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the margin for improvement shown in the Time Distributed LSTM training graph we shall try one last training and hyperparameter tuning with more epochs to see if it actually improves.\n",
    "\n",
    "Edit: after a first attempt to tune the hyperparameters, we've decided to drop the ADAM parameter assessment since it has already been somewhat evaluated and only try to vary the batch size on the ADAMAX optimizer. This is due to the excessive comptuational power and time required for such a test. We would have set the patience to 7, the reason for such value is written in the comments, but to assess the ADAMAX optimizer without unnecessary operations we set the value to 3.\n",
    "\n",
    "Second Edit: after the second attempt, we came to the conclusion that this even simplified assessment is not feasable in the current stage of the project. This is due to the very erratic nature of the test loss curve which can't be conteracted with Early Stopping. We believe this is caused by the high sensibility of the model to noise, which makes the test loss fluctuate and stay under the patience threshold and so not early stopping, even if it oughted to stop.\n",
    "\n",
    "The history files of the attempts were stored but the decision came mainly from looking at the on time outputs of the model's behaviour. For the ADAMAX independently of batch size we observed a peak of training accuracy (1.0000) and subsequent plateau around epoch 40 which lasted for the remaining epochs not achieving better test results meanwhile. We ran a last test on the TD-LSTM with batch size 32 and ADAM optimizer during 100 epochs to confirm the hypothesis proposed in the previous evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 9s 133ms/step - loss: 2.1665 - sparse_categorical_accuracy: 0.3108 - val_loss: 2.5302 - val_sparse_categorical_accuracy: 0.1959\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 1.1073 - sparse_categorical_accuracy: 0.7387 - val_loss: 2.6206 - val_sparse_categorical_accuracy: 0.2955\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.6777 - sparse_categorical_accuracy: 0.8739 - val_loss: 2.9161 - val_sparse_categorical_accuracy: 0.3036\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.4886 - sparse_categorical_accuracy: 0.9493 - val_loss: 3.0382 - val_sparse_categorical_accuracy: 0.3013\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.3870 - sparse_categorical_accuracy: 0.9764 - val_loss: 3.1528 - val_sparse_categorical_accuracy: 0.3253\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.3245 - sparse_categorical_accuracy: 0.9831 - val_loss: 3.3338 - val_sparse_categorical_accuracy: 0.3139\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.2837 - sparse_categorical_accuracy: 0.9921 - val_loss: 3.4760 - val_sparse_categorical_accuracy: 0.3242\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.2542 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5724 - val_sparse_categorical_accuracy: 0.3219\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.2298 - sparse_categorical_accuracy: 0.9966 - val_loss: 3.6188 - val_sparse_categorical_accuracy: 0.3379\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.2058 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6662 - val_sparse_categorical_accuracy: 0.3310\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1940 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.6572 - val_sparse_categorical_accuracy: 0.3230\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.1773 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.8185 - val_sparse_categorical_accuracy: 0.3276\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1667 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8289 - val_sparse_categorical_accuracy: 0.3265\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1534 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.8497 - val_sparse_categorical_accuracy: 0.3299\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1402 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8825 - val_sparse_categorical_accuracy: 0.3276\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.1319 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7999 - val_sparse_categorical_accuracy: 0.3368\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1232 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9448 - val_sparse_categorical_accuracy: 0.3402\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.1158 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7338 - val_sparse_categorical_accuracy: 0.3356\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1082 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8397 - val_sparse_categorical_accuracy: 0.3471\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.1046 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9422 - val_sparse_categorical_accuracy: 0.3391\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.8501 - val_sparse_categorical_accuracy: 0.3517\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0916 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7693 - val_sparse_categorical_accuracy: 0.3345\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0896 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9450 - val_sparse_categorical_accuracy: 0.3288\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0827 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0443 - val_sparse_categorical_accuracy: 0.3425\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0781 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0686 - val_sparse_categorical_accuracy: 0.3391\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0721 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9743 - val_sparse_categorical_accuracy: 0.3368\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0698 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9274 - val_sparse_categorical_accuracy: 0.3414\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0657 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9321 - val_sparse_categorical_accuracy: 0.3368\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0649 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9649 - val_sparse_categorical_accuracy: 0.3310\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0619 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1376 - val_sparse_categorical_accuracy: 0.3288\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0595 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9226 - val_sparse_categorical_accuracy: 0.3265\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0562 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0273 - val_sparse_categorical_accuracy: 0.3436\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0539 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9994 - val_sparse_categorical_accuracy: 0.3414\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0541 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8997 - val_sparse_categorical_accuracy: 0.3345\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0516 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0424 - val_sparse_categorical_accuracy: 0.3414\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.0492 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8889 - val_sparse_categorical_accuracy: 0.3436\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0482 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1821 - val_sparse_categorical_accuracy: 0.3448\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0478 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.3033 - val_sparse_categorical_accuracy: 0.3345\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 0.0490 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1335 - val_sparse_categorical_accuracy: 0.3391\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0482 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1865 - val_sparse_categorical_accuracy: 0.3482\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0477 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1930 - val_sparse_categorical_accuracy: 0.3494\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0474 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0772 - val_sparse_categorical_accuracy: 0.3379\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0454 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.4489 - val_sparse_categorical_accuracy: 0.3746\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0440 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1997 - val_sparse_categorical_accuracy: 0.3597\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9977 - val_loss: 4.7883 - val_sparse_categorical_accuracy: 0.3345\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0687 - sparse_categorical_accuracy: 0.9966 - val_loss: 4.5707 - val_sparse_categorical_accuracy: 0.3310\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0649 - sparse_categorical_accuracy: 0.9989 - val_loss: 4.9864 - val_sparse_categorical_accuracy: 0.3391\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0547 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.6765 - val_sparse_categorical_accuracy: 0.3505\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0486 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.4840 - val_sparse_categorical_accuracy: 0.3608\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0428 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5240 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0388 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.2503 - val_sparse_categorical_accuracy: 0.3459\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0368 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.2057 - val_sparse_categorical_accuracy: 0.3425\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0358 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.2719 - val_sparse_categorical_accuracy: 0.3448\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0382 - sparse_categorical_accuracy: 0.9989 - val_loss: 4.4412 - val_sparse_categorical_accuracy: 0.3276\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0564 - sparse_categorical_accuracy: 0.9932 - val_loss: 4.0525 - val_sparse_categorical_accuracy: 0.3402\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0620 - sparse_categorical_accuracy: 0.9977 - val_loss: 5.2948 - val_sparse_categorical_accuracy: 0.3471\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0644 - sparse_categorical_accuracy: 0.9966 - val_loss: 5.5174 - val_sparse_categorical_accuracy: 0.3528\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0907 - sparse_categorical_accuracy: 0.9910 - val_loss: 5.8590 - val_sparse_categorical_accuracy: 0.3436\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1582 - sparse_categorical_accuracy: 0.9707 - val_loss: 4.9644 - val_sparse_categorical_accuracy: 0.3288\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1356 - sparse_categorical_accuracy: 0.9865 - val_loss: 6.1069 - val_sparse_categorical_accuracy: 0.3196\n",
      "Test accuracy 0 fold: 0.3195876181125641  TestLoss: 6.106874942779541\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 1.8334 - sparse_categorical_accuracy: 0.4330 - val_loss: 3.2450 - val_sparse_categorical_accuracy: 0.2804\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.7919 - sparse_categorical_accuracy: 0.8373 - val_loss: 3.1595 - val_sparse_categorical_accuracy: 0.3119\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.5080 - sparse_categorical_accuracy: 0.9439 - val_loss: 3.4245 - val_sparse_categorical_accuracy: 0.3086\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.3671 - sparse_categorical_accuracy: 0.9817 - val_loss: 3.3901 - val_sparse_categorical_accuracy: 0.3423\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.2996 - sparse_categorical_accuracy: 0.9943 - val_loss: 3.6898 - val_sparse_categorical_accuracy: 0.3131\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.2539 - sparse_categorical_accuracy: 0.9966 - val_loss: 3.7064 - val_sparse_categorical_accuracy: 0.3288\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.2276 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.5026 - val_sparse_categorical_accuracy: 0.3345\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.2023 - sparse_categorical_accuracy: 0.9966 - val_loss: 3.6863 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1801 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.5981 - val_sparse_categorical_accuracy: 0.3356\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1616 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5506 - val_sparse_categorical_accuracy: 0.3345\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1490 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.6079 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1361 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4656 - val_sparse_categorical_accuracy: 0.3345\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1286 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5443 - val_sparse_categorical_accuracy: 0.3255\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1177 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.4577 - val_sparse_categorical_accuracy: 0.3277\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.1095 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5043 - val_sparse_categorical_accuracy: 0.3311\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1022 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5409 - val_sparse_categorical_accuracy: 0.3243\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0970 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5805 - val_sparse_categorical_accuracy: 0.3243\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0957 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.5829 - val_sparse_categorical_accuracy: 0.3153\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1989 - sparse_categorical_accuracy: 0.9782 - val_loss: 3.4245 - val_sparse_categorical_accuracy: 0.3209\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.1122 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.6609 - val_sparse_categorical_accuracy: 0.3198\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0973 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7215 - val_sparse_categorical_accuracy: 0.3277\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0903 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6319 - val_sparse_categorical_accuracy: 0.3153\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0853 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5008 - val_sparse_categorical_accuracy: 0.3356\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0755 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6087 - val_sparse_categorical_accuracy: 0.3356\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0723 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6441 - val_sparse_categorical_accuracy: 0.3367\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0705 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7052 - val_sparse_categorical_accuracy: 0.3367\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0655 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6818 - val_sparse_categorical_accuracy: 0.3345\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0631 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5907 - val_sparse_categorical_accuracy: 0.3356\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0588 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5708 - val_sparse_categorical_accuracy: 0.3412\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0562 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5725 - val_sparse_categorical_accuracy: 0.3356\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0567 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6253 - val_sparse_categorical_accuracy: 0.3311\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0544 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5856 - val_sparse_categorical_accuracy: 0.3378\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0534 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5625 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0534 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7134 - val_sparse_categorical_accuracy: 0.3401\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0565 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.6062 - val_sparse_categorical_accuracy: 0.3412\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0518 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.5935 - val_sparse_categorical_accuracy: 0.3356\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 3s 100ms/step - loss: 0.0573 - sparse_categorical_accuracy: 0.9989 - val_loss: 4.0476 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0593 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8704 - val_sparse_categorical_accuracy: 0.3322\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0578 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1230 - val_sparse_categorical_accuracy: 0.3367\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0507 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9676 - val_sparse_categorical_accuracy: 0.3255\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0497 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7999 - val_sparse_categorical_accuracy: 0.3401\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0476 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8365 - val_sparse_categorical_accuracy: 0.3412\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0525 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0568 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0504 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.2916 - val_sparse_categorical_accuracy: 0.3142\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0462 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0643 - val_sparse_categorical_accuracy: 0.3356\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0418 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8629 - val_sparse_categorical_accuracy: 0.3288\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0403 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7508 - val_sparse_categorical_accuracy: 0.3390\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0394 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8298 - val_sparse_categorical_accuracy: 0.3322\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0400 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7188 - val_sparse_categorical_accuracy: 0.3277\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0421 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.8613 - val_sparse_categorical_accuracy: 0.3255\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0565 - sparse_categorical_accuracy: 0.9954 - val_loss: 4.1930 - val_sparse_categorical_accuracy: 0.3300\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0663 - sparse_categorical_accuracy: 0.9954 - val_loss: 4.5573 - val_sparse_categorical_accuracy: 0.3074\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0538 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1782 - val_sparse_categorical_accuracy: 0.3243\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0620 - sparse_categorical_accuracy: 0.9954 - val_loss: 4.2950 - val_sparse_categorical_accuracy: 0.3536\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1508 - sparse_categorical_accuracy: 0.9725 - val_loss: 5.5240 - val_sparse_categorical_accuracy: 0.3063\n",
      "Test accuracy 1 fold: 0.30630630254745483  TestLoss: 5.5239973068237305\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 1.7248 - sparse_categorical_accuracy: 0.4719 - val_loss: 3.3665 - val_sparse_categorical_accuracy: 0.3319\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.7240 - sparse_categorical_accuracy: 0.8545 - val_loss: 3.5592 - val_sparse_categorical_accuracy: 0.3557\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.5065 - sparse_categorical_accuracy: 0.9393 - val_loss: 3.7193 - val_sparse_categorical_accuracy: 0.2854\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.3701 - sparse_categorical_accuracy: 0.9828 - val_loss: 3.5385 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 0.3097 - sparse_categorical_accuracy: 0.9897 - val_loss: 3.8650 - val_sparse_categorical_accuracy: 0.3178\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.2639 - sparse_categorical_accuracy: 0.9931 - val_loss: 3.7884 - val_sparse_categorical_accuracy: 0.3276\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 0.2225 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.6774 - val_sparse_categorical_accuracy: 0.3286\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.1959 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6481 - val_sparse_categorical_accuracy: 0.3330\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.1739 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6294 - val_sparse_categorical_accuracy: 0.3330\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 0.1604 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6901 - val_sparse_categorical_accuracy: 0.3286\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1486 - sparse_categorical_accuracy: 0.9966 - val_loss: 3.8750 - val_sparse_categorical_accuracy: 0.3254\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1381 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6012 - val_sparse_categorical_accuracy: 0.3449\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.1219 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5247 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.1123 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5593 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.1039 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5354 - val_sparse_categorical_accuracy: 0.3481\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0959 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5838 - val_sparse_categorical_accuracy: 0.3384\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0910 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5890 - val_sparse_categorical_accuracy: 0.3459\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0873 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6573 - val_sparse_categorical_accuracy: 0.3341\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0810 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5066 - val_sparse_categorical_accuracy: 0.3438\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0781 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5661 - val_sparse_categorical_accuracy: 0.3395\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0760 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.5923 - val_sparse_categorical_accuracy: 0.3276\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0735 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.6771 - val_sparse_categorical_accuracy: 0.3232\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0782 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.6278 - val_sparse_categorical_accuracy: 0.3384\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0862 - sparse_categorical_accuracy: 0.9966 - val_loss: 3.7996 - val_sparse_categorical_accuracy: 0.3341\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.9370 - val_sparse_categorical_accuracy: 0.3297\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0656 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8223 - val_sparse_categorical_accuracy: 0.3351\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0616 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6769 - val_sparse_categorical_accuracy: 0.3319\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0587 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7987 - val_sparse_categorical_accuracy: 0.3405\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0574 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7101 - val_sparse_categorical_accuracy: 0.3481\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0548 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6627 - val_sparse_categorical_accuracy: 0.3351\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0517 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7701 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0513 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7405 - val_sparse_categorical_accuracy: 0.3578\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0492 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7411 - val_sparse_categorical_accuracy: 0.3373\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0477 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6719 - val_sparse_categorical_accuracy: 0.3351\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0480 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7491 - val_sparse_categorical_accuracy: 0.3459\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0467 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7160 - val_sparse_categorical_accuracy: 0.3362\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.0456 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6998 - val_sparse_categorical_accuracy: 0.3211\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0453 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6456 - val_sparse_categorical_accuracy: 0.3449\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0714 - sparse_categorical_accuracy: 0.9920 - val_loss: 3.8204 - val_sparse_categorical_accuracy: 0.3589\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9943 - val_loss: 4.2948 - val_sparse_categorical_accuracy: 0.3330\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0593 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.3739 - val_sparse_categorical_accuracy: 0.3124\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0542 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.3118 - val_sparse_categorical_accuracy: 0.3341\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0474 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1284 - val_sparse_categorical_accuracy: 0.3265\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 0.0436 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9442 - val_sparse_categorical_accuracy: 0.3243\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0415 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9131 - val_sparse_categorical_accuracy: 0.3330\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0405 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9680 - val_sparse_categorical_accuracy: 0.3276\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0385 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8711 - val_sparse_categorical_accuracy: 0.3373\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0376 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7934 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0357 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8258 - val_sparse_categorical_accuracy: 0.3286\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0361 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8039 - val_sparse_categorical_accuracy: 0.3297\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0359 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9052 - val_sparse_categorical_accuracy: 0.3449\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0361 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9718 - val_sparse_categorical_accuracy: 0.3362\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 0.0346 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9680 - val_sparse_categorical_accuracy: 0.3362\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0337 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8788 - val_sparse_categorical_accuracy: 0.3319\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0327 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9643 - val_sparse_categorical_accuracy: 0.3103\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0321 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0208 - val_sparse_categorical_accuracy: 0.3297\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0316 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9976 - val_sparse_categorical_accuracy: 0.3254\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.0344 - sparse_categorical_accuracy: 0.9977 - val_loss: 4.0585 - val_sparse_categorical_accuracy: 0.3005\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0533 - sparse_categorical_accuracy: 0.9931 - val_loss: 4.2336 - val_sparse_categorical_accuracy: 0.3243\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9828 - val_loss: 4.9667 - val_sparse_categorical_accuracy: 0.3059\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1310 - sparse_categorical_accuracy: 0.9840 - val_loss: 5.1463 - val_sparse_categorical_accuracy: 0.3351\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.1252 - sparse_categorical_accuracy: 0.9954 - val_loss: 5.1912 - val_sparse_categorical_accuracy: 0.3341\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.1196 - sparse_categorical_accuracy: 0.9897 - val_loss: 5.0123 - val_sparse_categorical_accuracy: 0.2973\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.1123 - sparse_categorical_accuracy: 0.9920 - val_loss: 5.1472 - val_sparse_categorical_accuracy: 0.3092\n",
      "Test accuracy 2 fold: 0.30918920040130615  TestLoss: 5.147202491760254\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 1.8451 - sparse_categorical_accuracy: 0.4399 - val_loss: 2.6689 - val_sparse_categorical_accuracy: 0.2990\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.7743 - sparse_categorical_accuracy: 0.8396 - val_loss: 3.2705 - val_sparse_categorical_accuracy: 0.2828\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.5072 - sparse_categorical_accuracy: 0.9347 - val_loss: 3.3851 - val_sparse_categorical_accuracy: 0.2687\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.3656 - sparse_categorical_accuracy: 0.9805 - val_loss: 3.6133 - val_sparse_categorical_accuracy: 0.2616\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 3s 103ms/step - loss: 0.3028 - sparse_categorical_accuracy: 0.9908 - val_loss: 3.2925 - val_sparse_categorical_accuracy: 0.2798\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.2541 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.3724 - val_sparse_categorical_accuracy: 0.2970\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.2249 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.3306 - val_sparse_categorical_accuracy: 0.2768\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1975 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2904 - val_sparse_categorical_accuracy: 0.3000\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.1758 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3058 - val_sparse_categorical_accuracy: 0.2960\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.1675 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.2960 - val_sparse_categorical_accuracy: 0.2899\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.1532 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.3004 - val_sparse_categorical_accuracy: 0.3040\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.1363 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3976 - val_sparse_categorical_accuracy: 0.2909\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.1263 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.3370 - val_sparse_categorical_accuracy: 0.2909\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.1144 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3597 - val_sparse_categorical_accuracy: 0.2899\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.1039 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3045 - val_sparse_categorical_accuracy: 0.2889\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 3s 100ms/step - loss: 0.0988 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3180 - val_sparse_categorical_accuracy: 0.2808\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0914 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2629 - val_sparse_categorical_accuracy: 0.2879\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 3s 101ms/step - loss: 0.0888 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3762 - val_sparse_categorical_accuracy: 0.2788\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0840 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2732 - val_sparse_categorical_accuracy: 0.2899\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0798 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3163 - val_sparse_categorical_accuracy: 0.3030\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0766 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.3365 - val_sparse_categorical_accuracy: 0.2919\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.4280 - val_sparse_categorical_accuracy: 0.2808\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0718 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4203 - val_sparse_categorical_accuracy: 0.3040\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0679 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3848 - val_sparse_categorical_accuracy: 0.2960\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0656 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4158 - val_sparse_categorical_accuracy: 0.2909\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0629 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4027 - val_sparse_categorical_accuracy: 0.2889\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0598 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4396 - val_sparse_categorical_accuracy: 0.2970\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0567 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4750 - val_sparse_categorical_accuracy: 0.2737\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0565 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3374 - val_sparse_categorical_accuracy: 0.3040\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 3s 101ms/step - loss: 0.0578 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4506 - val_sparse_categorical_accuracy: 0.2879\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 0.0543 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4154 - val_sparse_categorical_accuracy: 0.2889\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.4886 - val_sparse_categorical_accuracy: 0.2808\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0527 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5207 - val_sparse_categorical_accuracy: 0.2838\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.0499 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4592 - val_sparse_categorical_accuracy: 0.2899\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0504 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5680 - val_sparse_categorical_accuracy: 0.2747\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0481 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5263 - val_sparse_categorical_accuracy: 0.2949\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 0.0464 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4371 - val_sparse_categorical_accuracy: 0.2869\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0474 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5897 - val_sparse_categorical_accuracy: 0.2707\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0462 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6023 - val_sparse_categorical_accuracy: 0.2798\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0440 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4253 - val_sparse_categorical_accuracy: 0.2949\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0508 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7156 - val_sparse_categorical_accuracy: 0.2879\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 3s 101ms/step - loss: 0.0522 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6195 - val_sparse_categorical_accuracy: 0.2919\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9966 - val_loss: 3.8817 - val_sparse_categorical_accuracy: 0.2737\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0569 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0319 - val_sparse_categorical_accuracy: 0.2788\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0499 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8171 - val_sparse_categorical_accuracy: 0.2828\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0463 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6456 - val_sparse_categorical_accuracy: 0.2848\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0436 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6729 - val_sparse_categorical_accuracy: 0.2818\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0417 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5353 - val_sparse_categorical_accuracy: 0.2939\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 0.0391 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5155 - val_sparse_categorical_accuracy: 0.3040\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0367 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7184 - val_sparse_categorical_accuracy: 0.2970\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0354 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5942 - val_sparse_categorical_accuracy: 0.2889\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0349 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5618 - val_sparse_categorical_accuracy: 0.2960\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.0322 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5016 - val_sparse_categorical_accuracy: 0.3040\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0325 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5320 - val_sparse_categorical_accuracy: 0.2818\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0345 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5730 - val_sparse_categorical_accuracy: 0.3051\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0359 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8950 - val_sparse_categorical_accuracy: 0.2818\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 3s 101ms/step - loss: 0.0381 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7598 - val_sparse_categorical_accuracy: 0.2727\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0554 - sparse_categorical_accuracy: 0.9943 - val_loss: 4.0293 - val_sparse_categorical_accuracy: 0.2919\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.1397 - sparse_categorical_accuracy: 0.9759 - val_loss: 4.9441 - val_sparse_categorical_accuracy: 0.2909\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 3s 102ms/step - loss: 0.1576 - sparse_categorical_accuracy: 0.9782 - val_loss: 4.4538 - val_sparse_categorical_accuracy: 0.2798\n",
      "Test accuracy 3 fold: 0.2797979712486267  TestLoss: 4.453838348388672\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 1.7431 - sparse_categorical_accuracy: 0.4616 - val_loss: 2.6568 - val_sparse_categorical_accuracy: 0.3472\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.8331 - sparse_categorical_accuracy: 0.8293 - val_loss: 2.7245 - val_sparse_categorical_accuracy: 0.3739\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.5400 - sparse_categorical_accuracy: 0.9221 - val_loss: 3.0328 - val_sparse_categorical_accuracy: 0.3675\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.3732 - sparse_categorical_accuracy: 0.9863 - val_loss: 3.0373 - val_sparse_categorical_accuracy: 0.3825\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.2886 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.0769 - val_sparse_categorical_accuracy: 0.3857\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.2543 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.0934 - val_sparse_categorical_accuracy: 0.3835\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.2199 - sparse_categorical_accuracy: 0.9989 - val_loss: 2.9378 - val_sparse_categorical_accuracy: 0.4113\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.1928 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9172 - val_sparse_categorical_accuracy: 0.4017\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1751 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8937 - val_sparse_categorical_accuracy: 0.3942\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.1569 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9121 - val_sparse_categorical_accuracy: 0.3985\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1434 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8511 - val_sparse_categorical_accuracy: 0.3996\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.1341 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8349 - val_sparse_categorical_accuracy: 0.4156\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1230 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8913 - val_sparse_categorical_accuracy: 0.3974\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1232 - sparse_categorical_accuracy: 0.9977 - val_loss: 2.8598 - val_sparse_categorical_accuracy: 0.4060\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1082 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8590 - val_sparse_categorical_accuracy: 0.4145\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1030 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8688 - val_sparse_categorical_accuracy: 0.3964\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0950 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9035 - val_sparse_categorical_accuracy: 0.3910\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0904 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8360 - val_sparse_categorical_accuracy: 0.4060\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0884 - sparse_categorical_accuracy: 0.9989 - val_loss: 2.8792 - val_sparse_categorical_accuracy: 0.4188\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0815 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8662 - val_sparse_categorical_accuracy: 0.4028\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0772 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8929 - val_sparse_categorical_accuracy: 0.4049\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0751 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9645 - val_sparse_categorical_accuracy: 0.4017\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0732 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8696 - val_sparse_categorical_accuracy: 0.4188\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0687 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9315 - val_sparse_categorical_accuracy: 0.3974\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0661 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9252 - val_sparse_categorical_accuracy: 0.4177\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0635 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0056 - val_sparse_categorical_accuracy: 0.4103\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0637 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8928 - val_sparse_categorical_accuracy: 0.3900\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9989 - val_loss: 2.9710 - val_sparse_categorical_accuracy: 0.4241\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0591 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1847 - val_sparse_categorical_accuracy: 0.3814\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0575 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0096 - val_sparse_categorical_accuracy: 0.4113\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0562 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9622 - val_sparse_categorical_accuracy: 0.4092\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0553 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9574 - val_sparse_categorical_accuracy: 0.4124\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0526 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0622 - val_sparse_categorical_accuracy: 0.3964\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0501 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9670 - val_sparse_categorical_accuracy: 0.4135\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0490 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0353 - val_sparse_categorical_accuracy: 0.3996\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0508 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0143 - val_sparse_categorical_accuracy: 0.4049\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 3s 89ms/step - loss: 0.0493 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0019 - val_sparse_categorical_accuracy: 0.4103\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0521 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.2911 - val_sparse_categorical_accuracy: 0.3782\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0502 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3321 - val_sparse_categorical_accuracy: 0.4135\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0482 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1584 - val_sparse_categorical_accuracy: 0.4060\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0449 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2340 - val_sparse_categorical_accuracy: 0.4028\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0467 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1965 - val_sparse_categorical_accuracy: 0.4231\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0475 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1460 - val_sparse_categorical_accuracy: 0.4092\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0465 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6170 - val_sparse_categorical_accuracy: 0.3825\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0442 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3010 - val_sparse_categorical_accuracy: 0.4071\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0531 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.2214 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0476 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1966 - val_sparse_categorical_accuracy: 0.4241\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0435 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3403 - val_sparse_categorical_accuracy: 0.3889\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0405 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1275 - val_sparse_categorical_accuracy: 0.4199\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0387 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1153 - val_sparse_categorical_accuracy: 0.4263\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0366 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1282 - val_sparse_categorical_accuracy: 0.4177\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0356 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1973 - val_sparse_categorical_accuracy: 0.4092\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0354 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2734 - val_sparse_categorical_accuracy: 0.3953\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0352 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2249 - val_sparse_categorical_accuracy: 0.4156\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0331 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1487 - val_sparse_categorical_accuracy: 0.4209\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0323 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3410 - val_sparse_categorical_accuracy: 0.3825\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0316 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2836 - val_sparse_categorical_accuracy: 0.4049\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0324 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2001 - val_sparse_categorical_accuracy: 0.3932\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0330 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3491 - val_sparse_categorical_accuracy: 0.3921\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0502 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.8182 - val_sparse_categorical_accuracy: 0.3697\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0607 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.9031 - val_sparse_categorical_accuracy: 0.3782\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0961 - sparse_categorical_accuracy: 0.9885 - val_loss: 3.3776 - val_sparse_categorical_accuracy: 0.3686\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0980 - sparse_categorical_accuracy: 0.9885 - val_loss: 4.0898 - val_sparse_categorical_accuracy: 0.3782\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.1044 - sparse_categorical_accuracy: 0.9908 - val_loss: 3.9942 - val_sparse_categorical_accuracy: 0.4038\n",
      "Test accuracy 4 fold: 0.4038461446762085  TestLoss: 3.994152784347534\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 1.7427 - sparse_categorical_accuracy: 0.4800 - val_loss: 3.6185 - val_sparse_categorical_accuracy: 0.2612\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 0.8324 - sparse_categorical_accuracy: 0.8305 - val_loss: 3.4959 - val_sparse_categorical_accuracy: 0.3147\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.5243 - sparse_categorical_accuracy: 0.9336 - val_loss: 3.6377 - val_sparse_categorical_accuracy: 0.2880\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.3856 - sparse_categorical_accuracy: 0.9805 - val_loss: 3.6079 - val_sparse_categorical_accuracy: 0.3147\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.3032 - sparse_categorical_accuracy: 0.9920 - val_loss: 3.5797 - val_sparse_categorical_accuracy: 0.3062\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.2506 - sparse_categorical_accuracy: 0.9966 - val_loss: 3.6735 - val_sparse_categorical_accuracy: 0.2989\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.2184 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6561 - val_sparse_categorical_accuracy: 0.3001\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.1875 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5854 - val_sparse_categorical_accuracy: 0.2989\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.1678 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5393 - val_sparse_categorical_accuracy: 0.2989\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.1527 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.5481 - val_sparse_categorical_accuracy: 0.2892\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.1349 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5834 - val_sparse_categorical_accuracy: 0.2977\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1254 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5213 - val_sparse_categorical_accuracy: 0.3062\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1196 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.4939 - val_sparse_categorical_accuracy: 0.2965\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1083 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5328 - val_sparse_categorical_accuracy: 0.3050\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.1011 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5798 - val_sparse_categorical_accuracy: 0.2953\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0941 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5759 - val_sparse_categorical_accuracy: 0.2940\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0888 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5378 - val_sparse_categorical_accuracy: 0.3026\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0841 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5782 - val_sparse_categorical_accuracy: 0.2916\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0795 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6414 - val_sparse_categorical_accuracy: 0.2928\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0744 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5652 - val_sparse_categorical_accuracy: 0.3038\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0707 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5478 - val_sparse_categorical_accuracy: 0.2965\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0709 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5706 - val_sparse_categorical_accuracy: 0.2940\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0749 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.5370 - val_sparse_categorical_accuracy: 0.3147\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0741 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6955 - val_sparse_categorical_accuracy: 0.3050\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0650 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7452 - val_sparse_categorical_accuracy: 0.3123\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0624 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7234 - val_sparse_categorical_accuracy: 0.2989\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0622 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8854 - val_sparse_categorical_accuracy: 0.2916\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0609 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7296 - val_sparse_categorical_accuracy: 0.2928\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0567 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7284 - val_sparse_categorical_accuracy: 0.2965\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0543 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7117 - val_sparse_categorical_accuracy: 0.2940\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0537 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9305 - val_sparse_categorical_accuracy: 0.3013\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0520 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8379 - val_sparse_categorical_accuracy: 0.2977\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0498 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8381 - val_sparse_categorical_accuracy: 0.2953\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0477 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8453 - val_sparse_categorical_accuracy: 0.2928\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0470 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8428 - val_sparse_categorical_accuracy: 0.3013\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0464 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9589 - val_sparse_categorical_accuracy: 0.2989\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0451 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8379 - val_sparse_categorical_accuracy: 0.2928\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0458 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.7947 - val_sparse_categorical_accuracy: 0.2977\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0448 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9658 - val_sparse_categorical_accuracy: 0.3050\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0473 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0715 - val_sparse_categorical_accuracy: 0.3074\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 0.0486 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0996 - val_sparse_categorical_accuracy: 0.3147\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0438 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1667 - val_sparse_categorical_accuracy: 0.3123\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0408 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0600 - val_sparse_categorical_accuracy: 0.2928\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0418 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0514 - val_sparse_categorical_accuracy: 0.2831\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0392 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9971 - val_sparse_categorical_accuracy: 0.2855\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0380 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0462 - val_sparse_categorical_accuracy: 0.3050\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0396 - sparse_categorical_accuracy: 0.9989 - val_loss: 4.1492 - val_sparse_categorical_accuracy: 0.2965\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9966 - val_loss: 4.5012 - val_sparse_categorical_accuracy: 0.2710\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9966 - val_loss: 5.0453 - val_sparse_categorical_accuracy: 0.2807\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 0.1282 - sparse_categorical_accuracy: 0.9817 - val_loss: 5.4383 - val_sparse_categorical_accuracy: 0.2588\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.1211 - sparse_categorical_accuracy: 0.9920 - val_loss: 5.7115 - val_sparse_categorical_accuracy: 0.2612\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9966 - val_loss: 5.1572 - val_sparse_categorical_accuracy: 0.2953\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0899 - sparse_categorical_accuracy: 0.9989 - val_loss: 5.1142 - val_sparse_categorical_accuracy: 0.2965\n",
      "Test accuracy 5 fold: 0.2964763045310974  TestLoss: 5.114160060882568\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 1.7977 - sparse_categorical_accuracy: 0.4433 - val_loss: 2.6437 - val_sparse_categorical_accuracy: 0.3377\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.8172 - sparse_categorical_accuracy: 0.8419 - val_loss: 3.0957 - val_sparse_categorical_accuracy: 0.3234\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.5488 - sparse_categorical_accuracy: 0.9210 - val_loss: 3.1030 - val_sparse_categorical_accuracy: 0.3449\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.3973 - sparse_categorical_accuracy: 0.9748 - val_loss: 3.2107 - val_sparse_categorical_accuracy: 0.3616\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.3058 - sparse_categorical_accuracy: 0.9931 - val_loss: 3.1141 - val_sparse_categorical_accuracy: 0.3520\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.2536 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.1531 - val_sparse_categorical_accuracy: 0.3568\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.2199 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0900 - val_sparse_categorical_accuracy: 0.3592\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1957 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1074 - val_sparse_categorical_accuracy: 0.3687\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.1727 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.0922 - val_sparse_categorical_accuracy: 0.3544\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1535 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0705 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1409 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0379 - val_sparse_categorical_accuracy: 0.3604\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.1281 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9497 - val_sparse_categorical_accuracy: 0.3592\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1173 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9332 - val_sparse_categorical_accuracy: 0.3604\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1122 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9452 - val_sparse_categorical_accuracy: 0.3735\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 0.1039 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9390 - val_sparse_categorical_accuracy: 0.3783\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0946 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0151 - val_sparse_categorical_accuracy: 0.3675\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0899 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0605 - val_sparse_categorical_accuracy: 0.3628\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0865 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0811 - val_sparse_categorical_accuracy: 0.3628\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0836 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0045 - val_sparse_categorical_accuracy: 0.3699\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0786 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0017 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0739 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0451 - val_sparse_categorical_accuracy: 0.3687\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0696 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1422 - val_sparse_categorical_accuracy: 0.3496\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 0.0678 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9973 - val_sparse_categorical_accuracy: 0.3675\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0647 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0443 - val_sparse_categorical_accuracy: 0.3616\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0630 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0615 - val_sparse_categorical_accuracy: 0.3604\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0608 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0526 - val_sparse_categorical_accuracy: 0.3711\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0611 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0855 - val_sparse_categorical_accuracy: 0.3496\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0559 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1649 - val_sparse_categorical_accuracy: 0.3532\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0622 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.1775 - val_sparse_categorical_accuracy: 0.3628\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.3969 - val_sparse_categorical_accuracy: 0.3652\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0596 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4736 - val_sparse_categorical_accuracy: 0.3687\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0567 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3754 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0513 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3189 - val_sparse_categorical_accuracy: 0.3735\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0492 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2021 - val_sparse_categorical_accuracy: 0.3819\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.1647 - val_sparse_categorical_accuracy: 0.3687\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9966 - val_loss: 3.1956 - val_sparse_categorical_accuracy: 0.3878\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0739 - sparse_categorical_accuracy: 0.9966 - val_loss: 3.6859 - val_sparse_categorical_accuracy: 0.3329\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0957 - sparse_categorical_accuracy: 0.9920 - val_loss: 3.8224 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1218 - sparse_categorical_accuracy: 0.9863 - val_loss: 3.8427 - val_sparse_categorical_accuracy: 0.3413\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.1224 - sparse_categorical_accuracy: 0.9874 - val_loss: 3.5621 - val_sparse_categorical_accuracy: 0.3556\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.9072 - val_sparse_categorical_accuracy: 0.3508\n",
      "Test accuracy 6 fold: 0.35083532333374023  TestLoss: 3.9072296619415283\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 1.7370 - sparse_categorical_accuracy: 0.4742 - val_loss: 2.9383 - val_sparse_categorical_accuracy: 0.3642\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.8096 - sparse_categorical_accuracy: 0.8362 - val_loss: 3.2464 - val_sparse_categorical_accuracy: 0.3529\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.4822 - sparse_categorical_accuracy: 0.9462 - val_loss: 3.3757 - val_sparse_categorical_accuracy: 0.3755\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.3821 - sparse_categorical_accuracy: 0.9714 - val_loss: 3.4690 - val_sparse_categorical_accuracy: 0.3905\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 0.3202 - sparse_categorical_accuracy: 0.9840 - val_loss: 3.6406 - val_sparse_categorical_accuracy: 0.3817\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.2591 - sparse_categorical_accuracy: 0.9943 - val_loss: 3.7117 - val_sparse_categorical_accuracy: 0.3930\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.2227 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6861 - val_sparse_categorical_accuracy: 0.3917\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.1956 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.6813 - val_sparse_categorical_accuracy: 0.4018\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.1739 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6756 - val_sparse_categorical_accuracy: 0.4018\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1564 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6949 - val_sparse_categorical_accuracy: 0.3905\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.1378 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6428 - val_sparse_categorical_accuracy: 0.3955\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 0.1287 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6943 - val_sparse_categorical_accuracy: 0.3967\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.1199 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7140 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.1107 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7168 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.1044 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7059 - val_sparse_categorical_accuracy: 0.3917\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0977 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7013 - val_sparse_categorical_accuracy: 0.4018\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0917 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7745 - val_sparse_categorical_accuracy: 0.4093\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0856 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7557 - val_sparse_categorical_accuracy: 0.4005\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0826 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7190 - val_sparse_categorical_accuracy: 0.4080\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 0.0799 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7837 - val_sparse_categorical_accuracy: 0.4018\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0760 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7147 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0717 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7910 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0685 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7627 - val_sparse_categorical_accuracy: 0.4105\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0760 - sparse_categorical_accuracy: 0.9954 - val_loss: 3.8173 - val_sparse_categorical_accuracy: 0.3955\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0719 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.9765 - val_sparse_categorical_accuracy: 0.4155\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9954 - val_loss: 4.1660 - val_sparse_categorical_accuracy: 0.3955\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0758 - sparse_categorical_accuracy: 0.9989 - val_loss: 4.0580 - val_sparse_categorical_accuracy: 0.3955\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0675 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0001 - val_sparse_categorical_accuracy: 0.3917\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 0.0623 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0375 - val_sparse_categorical_accuracy: 0.4018\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.9394 - val_sparse_categorical_accuracy: 0.4243\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0571 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9924 - val_sparse_categorical_accuracy: 0.4030\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0534 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9385 - val_sparse_categorical_accuracy: 0.4143\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0541 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9606 - val_sparse_categorical_accuracy: 0.4155\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0515 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9918 - val_sparse_categorical_accuracy: 0.4205\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0480 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8571 - val_sparse_categorical_accuracy: 0.4193\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0475 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0407 - val_sparse_categorical_accuracy: 0.4055\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0457 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0158 - val_sparse_categorical_accuracy: 0.4105\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0443 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0140 - val_sparse_categorical_accuracy: 0.4030\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0447 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9798 - val_sparse_categorical_accuracy: 0.4155\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0430 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1659 - val_sparse_categorical_accuracy: 0.3717\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0421 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0464 - val_sparse_categorical_accuracy: 0.4068\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0401 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0306 - val_sparse_categorical_accuracy: 0.3830\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0390 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9206 - val_sparse_categorical_accuracy: 0.4268\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0410 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1154 - val_sparse_categorical_accuracy: 0.3892\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0380 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1953 - val_sparse_categorical_accuracy: 0.3955\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0387 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1497 - val_sparse_categorical_accuracy: 0.4030\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0367 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0865 - val_sparse_categorical_accuracy: 0.3980\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0374 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0706 - val_sparse_categorical_accuracy: 0.4018\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0369 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0108 - val_sparse_categorical_accuracy: 0.4080\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0356 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.0290 - val_sparse_categorical_accuracy: 0.4130\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0535 - sparse_categorical_accuracy: 0.9920 - val_loss: 4.1863 - val_sparse_categorical_accuracy: 0.4043\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1878 - sparse_categorical_accuracy: 0.9565 - val_loss: 5.5081 - val_sparse_categorical_accuracy: 0.3141\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.2208 - sparse_categorical_accuracy: 0.9611 - val_loss: 5.3079 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1955 - sparse_categorical_accuracy: 0.9805 - val_loss: 5.8027 - val_sparse_categorical_accuracy: 0.3429\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.1480 - sparse_categorical_accuracy: 0.9966 - val_loss: 5.4935 - val_sparse_categorical_accuracy: 0.3680\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1263 - sparse_categorical_accuracy: 0.9977 - val_loss: 5.4600 - val_sparse_categorical_accuracy: 0.3692\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9989 - val_loss: 5.2956 - val_sparse_categorical_accuracy: 0.3792\n",
      "Test accuracy 7 fold: 0.37922403216362  TestLoss: 5.295614242553711\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 1.8130 - sparse_categorical_accuracy: 0.4422 - val_loss: 2.3369 - val_sparse_categorical_accuracy: 0.3983\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.7534 - sparse_categorical_accuracy: 0.8373 - val_loss: 2.6258 - val_sparse_categorical_accuracy: 0.3725\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.5480 - sparse_categorical_accuracy: 0.9107 - val_loss: 2.7753 - val_sparse_categorical_accuracy: 0.4142\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.3723 - sparse_categorical_accuracy: 0.9748 - val_loss: 2.7890 - val_sparse_categorical_accuracy: 0.3995\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.3123 - sparse_categorical_accuracy: 0.9897 - val_loss: 2.8696 - val_sparse_categorical_accuracy: 0.3885\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.2693 - sparse_categorical_accuracy: 0.9943 - val_loss: 3.0054 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.2309 - sparse_categorical_accuracy: 0.9989 - val_loss: 2.9695 - val_sparse_categorical_accuracy: 0.4191\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.2022 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9178 - val_sparse_categorical_accuracy: 0.4179\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1803 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8925 - val_sparse_categorical_accuracy: 0.4179\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1628 - sparse_categorical_accuracy: 0.9989 - val_loss: 2.9566 - val_sparse_categorical_accuracy: 0.4105\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.1477 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8526 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1342 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8524 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1240 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.7998 - val_sparse_categorical_accuracy: 0.4179\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1145 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8816 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1081 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8280 - val_sparse_categorical_accuracy: 0.4265\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1005 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8119 - val_sparse_categorical_accuracy: 0.4032\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0967 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8111 - val_sparse_categorical_accuracy: 0.4301\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0891 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9211 - val_sparse_categorical_accuracy: 0.4203\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0853 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.7792 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0811 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8015 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0776 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8500 - val_sparse_categorical_accuracy: 0.4081\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9989 - val_loss: 2.8662 - val_sparse_categorical_accuracy: 0.4191\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0723 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8165 - val_sparse_categorical_accuracy: 0.4424\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0706 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8390 - val_sparse_categorical_accuracy: 0.4277\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0676 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8327 - val_sparse_categorical_accuracy: 0.4032\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0649 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.8930 - val_sparse_categorical_accuracy: 0.4093\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0620 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9329 - val_sparse_categorical_accuracy: 0.3971\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0596 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9963 - val_sparse_categorical_accuracy: 0.4130\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9989 - val_loss: 2.9844 - val_sparse_categorical_accuracy: 0.4044\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0582 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9592 - val_sparse_categorical_accuracy: 0.4203\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0563 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0241 - val_sparse_categorical_accuracy: 0.4265\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0555 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0033 - val_sparse_categorical_accuracy: 0.4203\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0538 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0765 - val_sparse_categorical_accuracy: 0.4020\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0506 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9808 - val_sparse_categorical_accuracy: 0.4179\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0483 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9651 - val_sparse_categorical_accuracy: 0.4240\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0473 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9657 - val_sparse_categorical_accuracy: 0.4032\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0456 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9004 - val_sparse_categorical_accuracy: 0.4130\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0446 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9364 - val_sparse_categorical_accuracy: 0.4044\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0433 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9939 - val_sparse_categorical_accuracy: 0.3909\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0473 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9903 - val_sparse_categorical_accuracy: 0.4105\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 2s 90ms/step - loss: 0.0461 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1251 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0471 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1332 - val_sparse_categorical_accuracy: 0.4179\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0437 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1459 - val_sparse_categorical_accuracy: 0.3958\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0418 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0554 - val_sparse_categorical_accuracy: 0.4056\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0394 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1773 - val_sparse_categorical_accuracy: 0.4007\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0378 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0196 - val_sparse_categorical_accuracy: 0.3983\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0365 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9935 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0388 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.1592 - val_sparse_categorical_accuracy: 0.4130\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0395 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2005 - val_sparse_categorical_accuracy: 0.4265\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0369 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0673 - val_sparse_categorical_accuracy: 0.4301\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0349 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1231 - val_sparse_categorical_accuracy: 0.4289\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.0352 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0840 - val_sparse_categorical_accuracy: 0.4081\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0365 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2480 - val_sparse_categorical_accuracy: 0.3799\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.0367 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2014 - val_sparse_categorical_accuracy: 0.3995\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0344 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1834 - val_sparse_categorical_accuracy: 0.4154\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0355 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3799 - val_sparse_categorical_accuracy: 0.3775\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0616 - sparse_categorical_accuracy: 0.9920 - val_loss: 4.3538 - val_sparse_categorical_accuracy: 0.3419\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1500 - sparse_categorical_accuracy: 0.9794 - val_loss: 5.2539 - val_sparse_categorical_accuracy: 0.3382\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.1718 - sparse_categorical_accuracy: 0.9759 - val_loss: 4.8275 - val_sparse_categorical_accuracy: 0.3664\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 0.1851 - sparse_categorical_accuracy: 0.9782 - val_loss: 4.7036 - val_sparse_categorical_accuracy: 0.3419\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1603 - sparse_categorical_accuracy: 0.9897 - val_loss: 5.0126 - val_sparse_categorical_accuracy: 0.3431\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.1300 - sparse_categorical_accuracy: 0.9966 - val_loss: 4.5479 - val_sparse_categorical_accuracy: 0.3456\n",
      "Test accuracy 8 fold: 0.34558823704719543  TestLoss: 4.547901153564453\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 1.8131 - sparse_categorical_accuracy: 0.4616 - val_loss: 2.9613 - val_sparse_categorical_accuracy: 0.3763\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.8090 - sparse_categorical_accuracy: 0.8305 - val_loss: 2.8177 - val_sparse_categorical_accuracy: 0.3477\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.4958 - sparse_categorical_accuracy: 0.9462 - val_loss: 3.0736 - val_sparse_categorical_accuracy: 0.3811\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.3836 - sparse_categorical_accuracy: 0.9679 - val_loss: 3.1520 - val_sparse_categorical_accuracy: 0.3680\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.2927 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.1442 - val_sparse_categorical_accuracy: 0.3823\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.2458 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.1953 - val_sparse_categorical_accuracy: 0.3572\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 3s 89ms/step - loss: 0.2138 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.1703 - val_sparse_categorical_accuracy: 0.3668\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1896 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1676 - val_sparse_categorical_accuracy: 0.3763\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1736 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1933 - val_sparse_categorical_accuracy: 0.3704\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.1543 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1616 - val_sparse_categorical_accuracy: 0.3728\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1416 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2063 - val_sparse_categorical_accuracy: 0.3907\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1357 - sparse_categorical_accuracy: 0.9989 - val_loss: 2.9938 - val_sparse_categorical_accuracy: 0.3990\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1253 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2016 - val_sparse_categorical_accuracy: 0.3799\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.1156 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1210 - val_sparse_categorical_accuracy: 0.3608\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1039 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2108 - val_sparse_categorical_accuracy: 0.3751\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0993 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1942 - val_sparse_categorical_accuracy: 0.3704\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0944 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2892 - val_sparse_categorical_accuracy: 0.3823\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0909 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.1960 - val_sparse_categorical_accuracy: 0.3787\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0920 - sparse_categorical_accuracy: 0.9966 - val_loss: 3.2404 - val_sparse_categorical_accuracy: 0.3799\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.2834 - val_sparse_categorical_accuracy: 0.3548\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0849 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2980 - val_sparse_categorical_accuracy: 0.3704\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0781 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2076 - val_sparse_categorical_accuracy: 0.3572\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0720 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3242 - val_sparse_categorical_accuracy: 0.3680\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0688 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2416 - val_sparse_categorical_accuracy: 0.3632\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0656 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2680 - val_sparse_categorical_accuracy: 0.3740\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0636 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2966 - val_sparse_categorical_accuracy: 0.3716\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0581 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2515 - val_sparse_categorical_accuracy: 0.3680\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0581 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3888 - val_sparse_categorical_accuracy: 0.3668\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0594 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1813 - val_sparse_categorical_accuracy: 0.3728\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0586 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4277 - val_sparse_categorical_accuracy: 0.3608\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0543 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5301 - val_sparse_categorical_accuracy: 0.3656\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0523 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5257 - val_sparse_categorical_accuracy: 0.3524\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0531 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4148 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0516 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4238 - val_sparse_categorical_accuracy: 0.3405\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0513 - sparse_categorical_accuracy: 0.9989 - val_loss: 3.3715 - val_sparse_categorical_accuracy: 0.3680\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0502 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2318 - val_sparse_categorical_accuracy: 0.3883\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0490 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3282 - val_sparse_categorical_accuracy: 0.3751\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0493 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6186 - val_sparse_categorical_accuracy: 0.3680\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0464 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5528 - val_sparse_categorical_accuracy: 0.3799\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0455 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6547 - val_sparse_categorical_accuracy: 0.3740\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0435 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4627 - val_sparse_categorical_accuracy: 0.3835\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0430 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4239 - val_sparse_categorical_accuracy: 0.3716\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0417 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4333 - val_sparse_categorical_accuracy: 0.3644\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0393 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4295 - val_sparse_categorical_accuracy: 0.3716\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0377 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3491 - val_sparse_categorical_accuracy: 0.3548\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0372 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3441 - val_sparse_categorical_accuracy: 0.3608\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0360 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5392 - val_sparse_categorical_accuracy: 0.3632\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0352 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5735 - val_sparse_categorical_accuracy: 0.3740\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0362 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4690 - val_sparse_categorical_accuracy: 0.3572\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0351 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3208 - val_sparse_categorical_accuracy: 0.3584\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0348 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4887 - val_sparse_categorical_accuracy: 0.3787\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0347 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4995 - val_sparse_categorical_accuracy: 0.3644\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 2s 89ms/step - loss: 0.0374 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5679 - val_sparse_categorical_accuracy: 0.3907\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0371 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8305 - val_sparse_categorical_accuracy: 0.3728\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0402 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6580 - val_sparse_categorical_accuracy: 0.3644\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0384 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7323 - val_sparse_categorical_accuracy: 0.3345\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0349 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7647 - val_sparse_categorical_accuracy: 0.3214\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0334 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5770 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.0308 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6539 - val_sparse_categorical_accuracy: 0.3548\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0318 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3750 - val_sparse_categorical_accuracy: 0.3274\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9874 - val_loss: 4.3045 - val_sparse_categorical_accuracy: 0.3262\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 0.1336 - sparse_categorical_accuracy: 0.9771 - val_loss: 4.4986 - val_sparse_categorical_accuracy: 0.3513\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1507 - sparse_categorical_accuracy: 0.9759 - val_loss: 4.7812 - val_sparse_categorical_accuracy: 0.3572\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.1588 - sparse_categorical_accuracy: 0.9805 - val_loss: 4.5244 - val_sparse_categorical_accuracy: 0.3536\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1258 - sparse_categorical_accuracy: 0.9931 - val_loss: 4.8114 - val_sparse_categorical_accuracy: 0.3393\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1093 - sparse_categorical_accuracy: 0.9943 - val_loss: 4.2359 - val_sparse_categorical_accuracy: 0.3489\n",
      "Test accuracy 9 fold: 0.34886500239372253  TestLoss: 4.2359137535095215\n",
      "Mean acc: 0.33397161364555356\n"
     ]
    }
   ],
   "source": [
    "input=layers.Input(shape=shapers)\n",
    "lc1=layers.LSTM(40,dropout=0.2,return_sequences=True)(input)  \n",
    "lc2=layers.LSTM(40,dropout=0.2,return_sequences=True)(input)                        \n",
    "concatenated=layers.concatenate([lc1,lc2])\n",
    "td=layers.TimeDistributed(layers.Dense(80))(concatenated)\n",
    "f=layers.Flatten()(td)            # number of labels\n",
    "dense=layers.Dense(10,kernel_regularizer='l2')(f)\n",
    "sft=layers.Softmax()(dense)\n",
    "th=layers.Activation(keras.activations.tanh)(sft)   \n",
    "lstm=keras.Model(inputs=input,outputs=th)\n",
    "\n",
    "\n",
    "callback=tf.keras.callbacks.EarlyStopping(monitor='loss',patience=7)  # we shall apply early stopping with a high patience level due to the second curve in the graph\n",
    "                                                                         # that we wish not to stop in the middle of, since the improvement happens after it\n",
    "epocas=100\n",
    "for b  in [32]:\n",
    "    for o in ['adam']:\n",
    "        lstm.compile(optimizer=o,loss='SparseCategoricalCrossentropy',metrics=[metrics.SparseCategoricalAccuracy()])#,metrics.AUC(multi_label=True,num_labels=10)])\n",
    "        lstm.save_weights('sets/.h5')\n",
    "        history,scores,mean_acc=crossvalidation_10fold(callback,lstm,listmfcc,listlabels,epocas,f'ltd/ltdlstm_b{b}_o{o}',b)\n",
    "        print(f\"Mean acc: {mean_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "name='ltdlstm'\n",
    "with open('histories/ltd/'+name+'_b32_oadam_history'+'_fold' + str(10), 'rb') as file:\n",
    "    history=pickle.load(file)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Loss','Test Loss'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe due to the stochastic nature of the module the training behaviour did not match the expected of the previous iteration and no conclusions could be taken from such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major conclusion that we can get from this project is that something didn't work quite as expected in terms of classification performance. Comparing with other researchers results and even with the general domain knowledge in the topic we would expect the RNN to have a significantly better performance in this task. Even with a very simple architecutre results should range from 60+ to 90+ percent of accuracy throughout the various folds (2).  \n",
    "\n",
    "The two main issues concerning our Recurrent Models' performance are certainly their tendency to overfit and noise sensibility. We understand that more could be done to solve these issues and the window is open for further development.\n",
    "\n",
    "It is also worth mentioning that the values given are referrent to the last epoch of each episode and the true best values are not stored but they're not far from the results shown. \n",
    "\n",
    "Since the conclusions relating to each particular model have been annotated in their respective comment cells we have nothing else to add to this epilogue except for one final note regarding the enitre procedure. Given the Deep nature of the models, the computational power and time needed to train and experiment were a huge bottleneck to the development of the architectures and their evaluation. For the RNN approach in particular we could perhaps take advantage of a deeper solution but the same wouldn't be feasable to a certain extent and wouldn't be compatible with experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \"Urban Sound Source Classification and Comparison\" - Yihua Yang, Ling Hong, Ke Liu, Chenwei Dai. USCD-EDU 2019.\n",
    "2. \"What's That Sounds? Machine Learning for Urban Sound Classification\" - Li. Jingyang, Wang. Yinuo, Zhu. Hao, Zhang. Yuhan. USCD-EDU 2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorfds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
